{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deac717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYR-\n",
    "\"\"\"\n",
    "Volumetric tumor burden metrics from PET (SUV) + 3D binary mask(s).\n",
    "\n",
    "Outputs per patient:\n",
    "- MTV_mL: Molecular Tumor Volume (sum of lesion volumes) in mL\n",
    "- TLA_mL: Total Lesion Activity = SUVmean * MTV (mL) [unitless SUV convention]\n",
    "- TLF_% : Total Lesion Fraction = 100 * TLA / BodyVolume_BW (unitless %)\n",
    "- LesionCount\n",
    "- SUVmean_global, SUVmax_global (over all lesion voxels)\n",
    "- Dmax_mm: max centroid-to-centroid distance between lesions (mm)\n",
    "- (Optional passthrough): Age\n",
    "\n",
    "Also writes a per-lesion CSV with: lesion label, volume (mL), centroid (mm),\n",
    "SUVmean, SUVmax, and lesion TLA (mL).\n",
    "\n",
    "Assumptions:\n",
    "- PET volume is in SUV units (already normalized, typically by body weight).\n",
    "- Mask and PET are in the same space/grid.\n",
    "- Body volume (mL) ≈ 1000 * body_mass_kg (density ~1 g/mL).\n",
    "- All patients are male; no height information (LBW not computed).\n",
    "\n",
    "You can keep the fixed voxel size override (VOXEL_SIZE_MM), or set to None to\n",
    "use NIfTI header spacing.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd  # for reading anthropometrics from Excel\n",
    "\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "from scipy.spatial import distance\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage import util\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# ------------------------\n",
    "# Configuration\n",
    "# ------------------------\n",
    "# If you want to force a fixed voxel size, set VOXEL_SIZE_MM to a 3-tuple.\n",
    "# To use header spacing instead, set VOXEL_SIZE_MM = None.\n",
    "VOXEL_SIZE_MM: Optional[Tuple[float, float, float]] = (4.07283, 4.07283, 4.07283)  # or None\n",
    "\n",
    "SEG_FOLDER = \"nifti_output_mask_anonymized\"   # folder with 3D binary masks\n",
    "PET_FOLDER = \"nifti_pet_suv\"                  # folder with PET NIfTI (SUV)\n",
    "ANTHRO_XLSX = \"clinical_wiith_tmtv_dmax_shared.xlsx\"  # Excel with PID, weight (kg), (optional) age\n",
    "ANTHRO_SHEET = 0                               # sheet index or name\n",
    "\n",
    "OUT_SUMMARY_CSV = \"tumor_burden_summary.csv\"\n",
    "OUT_LESIONS_CSV = \"tumor_burden_lesions.csv\"\n",
    "\n",
    "# Accept 1234_MASK.nii.gz or 1234_SEG.nii.gz etc.\n",
    "MASK_PATTERNS = [\n",
    "    re.compile(r\"^(\\d+)_MASK\\.nii(\\.gz)?$\", re.IGNORECASE),\n",
    "    re.compile(r\"^(\\d+)_SEG\\.nii(\\.gz)?$\",  re.IGNORECASE),\n",
    "    re.compile(r\"^(\\d+)\\.nii(\\.gz)?$\",      re.IGNORECASE),  # fallback: bare PID\n",
    "]\n",
    "\n",
    "# PET file name search templates per PID (in PET_FOLDER)\n",
    "PET_GLOBS = [\n",
    "    \"{pid}_PET.nii.gz\", \"{pid}_PET.nii\", \"{pid}_SUV.nii.gz\", \"{pid}_SUV.nii\",\n",
    "    \"{pid}.nii.gz\", \"{pid}.nii\", \"*{pid}*PET*.nii.gz\", \"*{pid}*PET*.nii\",\n",
    "    \"*{pid}*SUV*.nii.gz\", \"*{pid}*SUV*.nii\"\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Utilities\n",
    "# ------------------------\n",
    "\n",
    "def maybe_pid(fname: str) -> Optional[str]:\n",
    "    for pat in MASK_PATTERNS:\n",
    "        m = pat.match(fname)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_pet_for_pid(pid: str, folder: str) -> Optional[str]:\n",
    "    for pat in PET_GLOBS:\n",
    "        for path in glob.glob(os.path.join(folder, pat.format(pid=pid))):\n",
    "            if os.path.isfile(path):\n",
    "                return path\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_spacing_mm(img_nii: nib.Nifti1Image,\n",
    "                   override: Optional[Tuple[float, float, float]] = VOXEL_SIZE_MM\n",
    "                  ) -> Tuple[float, float, float]:\n",
    "    if override is not None:\n",
    "        return tuple(float(x) for x in override)\n",
    "    hdr_sp = img_nii.header.get_zooms()[:3]\n",
    "    return tuple(float(x) for x in hdr_sp)\n",
    "\n",
    "\n",
    "def to_zyx_spacing(xyz_spacing: Tuple[float, float, float]) -> Tuple[float, float, float]:\n",
    "    # skimage regionprops & EDT use array axis order (z, y, x)\n",
    "    x, y, z = xyz_spacing\n",
    "    return (z, y, x)\n",
    "\n",
    "\n",
    "def compute_mtv_mL(mask: np.ndarray, spacing_xyz_mm: Tuple[float, float, float]) -> float:\n",
    "    voxel_vol_mm3 = spacing_xyz_mm[0] * spacing_xyz_mm[1] * spacing_xyz_mm[2]\n",
    "    mm3 = int(mask.sum()) * voxel_vol_mm3\n",
    "    return float(mm3) / 1000.0  # mL\n",
    "\n",
    "\n",
    "def compute_regionprops(mask: np.ndarray) -> Tuple[np.ndarray, List]:\n",
    "    cc = util.img_as_ubyte(mask) > 0\n",
    "    lab = label(cc, connectivity=cc.ndim)  # 26-connectivity in 3D\n",
    "    props = regionprops(lab)\n",
    "    return lab, props\n",
    "\n",
    "\n",
    "def compute_dmax_mm(props: List, spacing_xyz_mm: Tuple[float, float, float]) -> float:\n",
    "    if len(props) == 0:\n",
    "        return 0.0\n",
    "    spacing_zyx = to_zyx_spacing(spacing_xyz_mm)\n",
    "\n",
    "    if len(props) == 1:\n",
    "        comp_mask = (props[0].image)  # local cropped mask\n",
    "        dt = distance_transform_edt(comp_mask.astype(bool), sampling=spacing_zyx)\n",
    "        return float(dt.max())\n",
    "\n",
    "    # Multiple lesions: centroid distances in physical units\n",
    "    cents_mm = []\n",
    "    for p in props:\n",
    "        cz, cy, cx = p.centroid  # (z, y, x)\n",
    "        cents_mm.append(np.array([cz * spacing_zyx[0], cy * spacing_zyx[1], cx * spacing_zyx[2]], dtype=float))\n",
    "\n",
    "    dmax = 0.0\n",
    "    for i in range(len(cents_mm)):\n",
    "        for j in range(i + 1, len(cents_mm)):\n",
    "            d = float(distance.euclidean(cents_mm[i], cents_mm[j]))\n",
    "            if d > dmax:\n",
    "                dmax = d\n",
    "    return dmax\n",
    "\n",
    "\n",
    "def lesion_metrics(mask_labeled: np.ndarray,\n",
    "                   props: List,\n",
    "                   pet_suv: Optional[np.ndarray],\n",
    "                   spacing_xyz_mm: Tuple[float, float, float]):\n",
    "    \"\"\"\n",
    "    Returns list of per-lesion dicts: label, voxels, volume_mL, centroid_mm (x,y,z),\n",
    "    SUVmean, SUVmax, TLA_mL.\n",
    "    \"\"\"\n",
    "    spacing_zyx = to_zyx_spacing(spacing_xyz_mm)\n",
    "    voxel_vol_mL = (spacing_xyz_mm[0] * spacing_xyz_mm[1] * spacing_xyz_mm[2]) / 1000.0\n",
    "\n",
    "    lesions = []\n",
    "    for p in props:\n",
    "        lbl = int(p.label)\n",
    "        voxels = int(p.area)\n",
    "        vol_mL = voxels * voxel_vol_mL\n",
    "\n",
    "        cz, cy, cx = p.centroid\n",
    "        centroid_mm = (\n",
    "            float(cx * spacing_zyx[2]),\n",
    "            float(cy * spacing_zyx[1]),\n",
    "            float(cz * spacing_zyx[0]),\n",
    "        )\n",
    "\n",
    "        suv_mean = None\n",
    "        suv_max = None\n",
    "        tla_mL = None\n",
    "\n",
    "        if pet_suv is not None:\n",
    "            lesion_mask = (mask_labeled == lbl)\n",
    "            lesion_vals = pet_suv[lesion_mask]\n",
    "            if lesion_vals.size > 0:\n",
    "                suv_mean = float(np.nanmean(lesion_vals))\n",
    "                suv_max = float(np.nanmax(lesion_vals))\n",
    "                # TLA under unitless-SUV convention = SUVmean * MTV(mL)\n",
    "                tla_mL = float(suv_mean * vol_mL)\n",
    "\n",
    "        lesions.append({\n",
    "            \"label\": lbl,\n",
    "            \"voxels\": voxels,\n",
    "            \"Volume_mL\": vol_mL,\n",
    "            \"CentroidX_mm\": centroid_mm[0],\n",
    "            \"CentroidY_mm\": centroid_mm[1],\n",
    "            \"CentroidZ_mm\": centroid_mm[2],\n",
    "            \"SUVmean\": suv_mean,\n",
    "            \"SUVmax\": suv_max,\n",
    "            \"TLA_mL\": tla_mL,\n",
    "        })\n",
    "    return lesions\n",
    "\n",
    "\n",
    "def global_pet_stats_over_mask(pet_suv: np.ndarray, mask_bool: np.ndarray) -> Tuple[Optional[float], Optional[float]]:\n",
    "    vals = pet_suv[mask_bool > 0]\n",
    "    if vals.size == 0:\n",
    "        return None, None\n",
    "    return float(np.nanmean(vals)), float(np.nanmax(vals))\n",
    "\n",
    "\n",
    "# --- BW-only body volume (all male, no height) ---\n",
    "\n",
    "def compute_body_volume_mL_BW(weight_kg: Optional[float]) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Compute body volume in mL assuming 1 kg ≈ 1000 mL.\n",
    "    Returns None if weight is missing.\n",
    "    \"\"\"\n",
    "    if weight_kg is None:\n",
    "        return None\n",
    "    return 1000.0 * float(weight_kg)\n",
    "\n",
    "\n",
    "def load_anthro_table_excel(path_xlsx: Optional[str],\n",
    "                            sheet=0,\n",
    "                            pid_candidates=(\"PID\", \"pid\", \"Id\", \"id\", \"PatientID\", \"Patient_Id\"),\n",
    "                            weight_candidates=(\"weight_kg\", \"Weight_kg\", \"weight (kg)\", \"Weight (kg)\", \"Weight\", \"weight\"),\n",
    "                            age_candidates=(\"Age\", \"age\", \"PatientAge\", \"patient_age\")) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Returns mapping PID -> dict(weight_kg, age).\n",
    "    Auto-detects PID, weight, and age column names from common variants.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    if not path_xlsx or not os.path.isfile(path_xlsx):\n",
    "        return out\n",
    "\n",
    "    df = pd.read_excel(path_xlsx, sheet_name=sheet)\n",
    "\n",
    "    def find_col(candidates):\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        # try case-insensitive match\n",
    "        lower_map = {c.lower(): c for c in df.columns}\n",
    "        for c in candidates:\n",
    "            if c.lower() in lower_map:\n",
    "                return lower_map[c.lower()]\n",
    "        return None\n",
    "\n",
    "    pid_col = find_col(pid_candidates)\n",
    "    wt_col  = find_col(weight_candidates)\n",
    "    age_col = find_col(age_candidates)\n",
    "\n",
    "    if pid_col is None:\n",
    "        raise ValueError(\"Could not find PID column in anthropometrics Excel.\")\n",
    "    # weight can be missing per-row; we still proceed.\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        pid = str(row.get(pid_col)).strip()\n",
    "        if not pid or pid.lower() in (\"nan\", \"none\"):\n",
    "            continue\n",
    "        w = row.get(wt_col) if wt_col in df.columns else None\n",
    "        a = row.get(age_col) if age_col in df.columns else None\n",
    "        try:\n",
    "            w_float = float(w) if w is not None and str(w).strip() not in (\"\", \"nan\", \"None\") else None\n",
    "        except Exception:\n",
    "            w_float = None\n",
    "        try:\n",
    "            a_float = float(a) if a is not None and str(a).strip() not in (\"\", \"nan\", \"None\") else None\n",
    "        except Exception:\n",
    "            a_float = None\n",
    "\n",
    "        out[pid] = {\"weight_kg\": w_float, \"age\": a_float}\n",
    "    return out\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Main batch\n",
    "# ------------------------\n",
    "\n",
    "def process_one(pid: str,\n",
    "                seg_path: str,\n",
    "                pet_path: Optional[str],\n",
    "                anthro: Dict[str, Dict]):\n",
    "    # Load mask\n",
    "    seg_nii = nib.load(seg_path)\n",
    "    spacing_xyz_mm = get_spacing_mm(seg_nii, VOXEL_SIZE_MM)\n",
    "    mask = np.asarray(seg_nii.dataobj)\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    # Optionally load PET (SUV)\n",
    "    pet = None\n",
    "    if pet_path and os.path.isfile(pet_path):\n",
    "        pet_nii = nib.load(pet_path)\n",
    "        pet = np.asarray(pet_nii.dataobj).astype(np.float32)\n",
    "        if pet.shape != mask.shape:\n",
    "            raise ValueError(f\"PET shape {pet.shape} does not match mask shape {mask.shape} for PID {pid}.\")\n",
    "\n",
    "    # MTV\n",
    "    mtv_mL = compute_mtv_mL(mask, spacing_xyz_mm)\n",
    "\n",
    "    # Label & lesion-wise\n",
    "    lab, props = compute_regionprops(mask)\n",
    "    lesions = lesion_metrics(lab, props, pet, spacing_xyz_mm)\n",
    "\n",
    "    # Global PET stats & TLA\n",
    "    suvmean_global, suvmax_global = (None, None)\n",
    "    tla_mL = None\n",
    "    if pet is not None:\n",
    "        suvmean_global, suvmax_global = global_pet_stats_over_mask(pet, mask)\n",
    "        # TLA equals sum over lesions (SUVmean_lesion * MTV_lesion)\n",
    "        if len(lesions) > 0:\n",
    "            tla_vals = [l[\"TLA_mL\"] for l in lesions if l[\"TLA_mL\"] is not None]\n",
    "            tla_mL = float(np.nansum(tla_vals)) if len(tla_vals) > 0 else None\n",
    "\n",
    "    # Dmax\n",
    "    dmax_mm = compute_dmax_mm(props, spacing_xyz_mm)\n",
    "\n",
    "    # Anthropometrics & TLF (BW only)\n",
    "    a = anthro.get(pid, {})\n",
    "    weight_kg = a.get(\"weight_kg\")\n",
    "    age = a.get(\"age\")\n",
    "\n",
    "    body_vol_bw_mL = compute_body_volume_mL_BW(weight_kg)\n",
    "\n",
    "    tlf_bw_pct = None\n",
    "    if tla_mL is not None and body_vol_bw_mL is not None and body_vol_bw_mL > 0:\n",
    "        tlf_bw_pct = 100.0 * float(tla_mL) / float(body_vol_bw_mL)\n",
    "\n",
    "    # Per-lesion rows (add PID)\n",
    "    for l in lesions:\n",
    "        l[\"PID\"] = pid\n",
    "\n",
    "    summary = {\n",
    "        \"PID\": pid,\n",
    "        \"Age\": age,\n",
    "        \"LesionCount\": len(props),\n",
    "        \"MTV_mL\": mtv_mL,\n",
    "        \"TLA_mL\": tla_mL,\n",
    "        \"TLF_%\": tlf_bw_pct,                 # BW-only\n",
    "        \"SUVmean_global\": suvmean_global,\n",
    "        \"SUVmax_global\": suvmax_global,\n",
    "        \"Dmax_mm\": dmax_mm,\n",
    "        \"BodyVol_BW_mL\": body_vol_bw_mL,     # for transparency/debugging\n",
    "        \"UsedSpacingX_mm\": spacing_xyz_mm[0],\n",
    "        \"UsedSpacingY_mm\": spacing_xyz_mm[1],\n",
    "        \"UsedSpacingZ_mm\": spacing_xyz_mm[2],\n",
    "        \"PET_file\": pet_path,\n",
    "        \"Mask_file\": seg_path,\n",
    "    }\n",
    "\n",
    "    return summary, lesions\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load anthropometrics (age, weight) from Excel\n",
    "    anthro = load_anthro_table_excel(ANTHRO_XLSX, sheet=ANTHRO_SHEET)\n",
    "\n",
    "    summaries = []\n",
    "    lesion_rows = []\n",
    "\n",
    "    for fname in sorted(os.listdir(SEG_FOLDER)):\n",
    "        pid = maybe_pid(fname)\n",
    "        if not pid:\n",
    "            continue\n",
    "        seg_path = os.path.join(SEG_FOLDER, fname)\n",
    "        pet_path = find_pet_for_pid(pid, PET_FOLDER)\n",
    "\n",
    "        try:\n",
    "            summary, lesions = process_one(pid, seg_path, pet_path, anthro)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] PID {pid} failed: {e}\")\n",
    "            # Minimal placeholder\n",
    "            summary = {\n",
    "                \"PID\": pid,\n",
    "                \"Age\": anthro.get(pid, {}).get(\"age\"),\n",
    "                \"LesionCount\": None,\n",
    "                \"MTV_mL\": None,\n",
    "                \"TLA_mL\": None,\n",
    "                \"TLF_%\": None,\n",
    "                \"SUVmean_global\": None,\n",
    "                \"SUVmax_global\": None,\n",
    "                \"Dmax_mm\": None,\n",
    "                \"BodyVol_BW_mL\": None,\n",
    "                \"UsedSpacingX_mm\": None,\n",
    "                \"UsedSpacingY_mm\": None,\n",
    "                \"UsedSpacingZ_mm\": None,\n",
    "                \"PET_file\": pet_path,\n",
    "                \"Mask_file\": seg_path,\n",
    "            }\n",
    "            lesions = []\n",
    "\n",
    "        summaries.append(summary)\n",
    "        lesion_rows.extend(lesions)\n",
    "\n",
    "    # Write CSVs\n",
    "    sum_fields = [\n",
    "        \"PID\", \"Age\", \"LesionCount\", \"MTV_mL\", \"TLA_mL\", \"TLF_%\",\n",
    "        \"SUVmean_global\", \"SUVmax_global\", \"Dmax_mm\",\n",
    "        \"BodyVol_BW_mL\",\n",
    "        \"UsedSpacingX_mm\", \"UsedSpacingY_mm\", \"UsedSpacingZ_mm\",\n",
    "        \"PET_file\", \"Mask_file\",\n",
    "    ]\n",
    "    with open(OUT_SUMMARY_CSV, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=sum_fields)\n",
    "        w.writeheader()\n",
    "        for r in summaries:\n",
    "            w.writerow(r)\n",
    "\n",
    "    lesion_fields = [\n",
    "        \"PID\", \"label\", \"voxels\", \"Volume_mL\",\n",
    "        \"CentroidX_mm\", \"CentroidY_mm\", \"CentroidZ_mm\",\n",
    "        \"SUVmean\", \"SUVmax\", \"TLA_mL\",\n",
    "    ]\n",
    "    with open(OUT_LESIONS_CSV, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=lesion_fields)\n",
    "        w.writeheader()\n",
    "        for r in lesion_rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "    print(f\"Done. Wrote {len(summaries)} patients to {OUT_SUMMARY_CSV} and {len(lesion_rows)} lesions to {OUT_LESIONS_CSV}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
